# 딥러닝

### 비선형 활성화 함수
- 선형 함수 : 전체 구간에서 동일한 기울기를 가지는 직선 -> 미분 결과가 상수
- 비선형 함수 <-> 선형함수

### ANN(Artificial Neural Network)
- Input layer + Hidden layer + Output layer
- 학습 과정은 지난주 딥다이브때 했으니까 패스

### FCNN(Fully Connected Nueral Network)
- 모든 뉴런이 이전 층의 모든 뉴런과 연결되는 구조 -> 이전 층의 모든 노드들이 다음 층의 모든 노드들의 Input으로 전달된다. 그물망구조
- 모델 평가 코드 해석
``` python
with torch.no_grad():
    for inputs, labels in test_loader:
        outputs = model(inputs) # 1. outputs은 test_loader에 설정한 batch 만큼 나온다. [batch_size, input_dim]
        _, predicted = torch.max(outputs.data, 1) # 2. outputs.data는 x_test =
        total += labels.size(0) # 3
        correct += (predicted == labels).sum().item()
```

### FCL(Fully Connected Layer)
- nn.Flatten() -> 배치사이즈는 남겨두고 나머지만 flatten

### 손실 함수
- MSE : 회귀 문제에서 평균 제곱 오차
- 크로스엔트로피 : 분류 문제에서 예측 확률과 실제 정답간의 차이를 최소화 하는 손실함수
  - 0이면 잘 맞춘거. 4면 극단적으로 못맞췄다.