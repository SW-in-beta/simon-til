# 심화학습

### 데이터 증강
- 데이터가 풍부해도 사용할 수 있다. 다양하게 변형할 수 있기 때문
  - 자율주행 데이터셋에 다양한 날씨나 조명 조건 반영해서 증강
- 데이터셋이 편향되어 있는 경우에도 사용하면 좋다.
  - 밝은 사진밖에 없을 때 등
- 일부러 노이즈를 줄 수도 있다!
  - 음성 인식 모델에 다양한 배경 소음을 추가하는 것도 필요
- 그렇다고 너무 불필요하게 증강할 필요는 없다.
  - 텍스트에 노이즈를 주겠답시고 랜덤 문자를 삽입한다거나...
  - 똑같은 사진을 여기저기 회전시켜서 넣는다거나...(사실상 중복 데이터기 때문에 과적합될 가능성이 크다.)

### GAN(Generative Adversarial N etworks)
- 이미지를 생성하는 Generator와 이미지를 구별하는 Discriminator를 싸우게 해서 둘다 성능을 올리는 것
  - Generator는 Discriminator를 속이기 위해서 계속 퀄리티 높은 이미지를 생성할거고, Discriminator는 강화학습을 통해 분류를 더 잘하게 된다.
  - 그렇지만 Main Objective는 Generator의 기능을 좋게 만드는 것
  - 누가 생각했는지 참 기발하다. 아이디어를 기억하고 있기
- 데이터 증강에 사용하면 좋을 것 같다.

### 데이터셋 분할
- 검증 데이터는 필수가 아니다.
  - 데이터 양이 부족할때는 굳이
  - 복잡한 모델에는 하이퍼파라미터가 많으니 검증 데이터가 있으면 좋다
  - 근데 굳이 검증 데이터 없어도 교차 검증 같은 방법으로 평가할 수 있긴 하다.

### 교차 검증(Cross Validation)
  - K-fold : 원본 데이터를 K개의 fold로 나누고, 1, 2, ..., K번째 fold를 검증 데이터로해서 반복적으로 두두두두
  - 근데 왜 안해도 되는거지? 예제만 봐서는 검증이 아니고 그냥 테스트 하는거 같은데.. 테스트만 여러번 하는거 아닌가?
    - 중간 중간에 K번의 테스트 자체가 검증이다! 그 테스트 결과들을 보면서 잘 학습이 되고 있나 검증할 수 있는 것.
    - 일반적으로 최종 테스트 데이터셋은 따로 둔다. 내 생각으로는 데이터셋 분할 시 학습 데이터 + 테스트 데이터로 분할하고 그 학습 데이터로 K-fold 교차검증을 하는 것 같다.