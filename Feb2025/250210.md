# 데이터 시각화

### 정형 데이터
- Row / Column 구조를 가진 체계적인 데이터(ex. 표, 데이터베이스)
- Column은 특정 데이터 유형(정수, 문자열 등)을 가짐 / Row는 개별 데이터 항목
- Pandas는 Database와 다르게 Row보다 Column에 관점을 둔다 -> Row가 많은 빅데이터는 Column 중심으로 바라보는 것이 의미있다(Alex 의견)
- Schema -> 설계도. Column의 이름 / 데이터 타입 / 제약 조건 등의 메타데이터를 담고 있다.

### 비정형 데이터
- 고정된 구조 없이 텍스트, 이미지, 영상, 오디오 등 다양한 형식으로 존재하는 데이터
- 스키마가 없는 NoSQL 데이터베이스도 포함(Mongo DB 등)
- 주로 대용량 데이터(ex. 센서로부터 수집된 데이터)
- 필요한 경우 정형화할 수 있음 / 수집 → 전처리 → 변환 → 분석 → 저장 과정을 거쳐 사용
- 비정형 데이터는 분석 전에 전처리(불필요한 정보 제거, 변환, 정리 등)가 필요한 경우가 많다.
  * 반정형 데이터 : 일부 구조는 있지만 고정된 스키마가 없음. 일반적으로 태그나 키-값 쌍의 형식으로 구성 (ex. JSON, XML 등). 제약이 약하다!
  * 크롤링 : 페이지 전체에 관심 / 스크래핑 : 페이지의 일부만 관심
  * 데이터를 수집하는 것은 기본적으로 Pandas / Numpy의 영역이 아니다. BS 등을 활용

### Matplotlib
- Mat : matrix-laboratory, plot : plotting, lib : library
- Line Plot : plt.plot()
- Bar Plot : plt.bar(), plt.barh() -> 가로형 막대그래프
- Box Plot / Scatter Plot etc...

### Seaborn
- 바다에서 태어난건 아니고, 드라마 등장인물 이름이다. 왜인지는 모른다.
- Matplotlib을 기반으로 하는 Python Library. 조금 더 높은 수준(더욱 추상화)에서 그래프를 그리는 도구.
- Matplotlib보다 조금 더 Pandas 친화적

### 데이터 관련 정리
- 범주형 데이터 : 명목형(Nominal, ex. 개 고양이) 또는 순서형(Ordinal, ex. 만족 보통 불만족)
  - Bar, Box, Violin Plot 등 활용해서 시각화
- 연속형 데이터
  - Histogram, Regression Line 등 활용해서 시각화
- 관계 데이터 : 주로 수치형 데이터 간의 상관관계를 분석할 때 활용
- 시계열 데이터 : 시간의 흐름에 따라 일정한 간격으로 측정된 연속적인 데이터
  - 시간에 따른 변화를 분석하여 미래를 예측하고 불확실성을 줄이기 위해 분석
  - 이동 평균을 활용하여 변동성을 줄이면서 추세 확인 가능
    - 이동 평균 : 시계열 데이터의 변동성을 완화하고 장기적인 추세를 파악하기 위해 일정 구간의 평균값을 계산하는 기법
    - 가중 이동 평균 등 다양한 계산법이 존재
- 합성 데이터 : 알고리즘을 활용하여 실제 세계의 데이터로부터 생성한 인공 데이터
  - Real Data를 학습한 OpenAI. 그리고 그 GPT가 생성한 합성 데이터를 학습한 DeepSeek
- 리샘플링 : 시계열 데이터의 분석을 위해 데이터의 시간 간격을 재조정하여 다운샘플링(축소)하거나 업샘플링(확대)하는 과정
  - 전체 데이터 집합을 대표할 수 있는 부분 집합(Sample)을 다시(Re) 추출하는 방식(Ing)
  - 다운샘플링 : 기존 데이터보다 더 긴 시간 간격으로 데이터 집계 -> 기존 데이터를 주어진 방식(mean, median 등)으로 집계하여 샘플링
  - 업샘플링 : 더 짧은 시간 간격으로 데이터 집계 -> 기존 데이터로 Interpolate하여 누락된 값 보충
- 금융 데이터 : 금융과 AI의 조합은 환상적 -> 주로 나스닥 등에서 제공하는 유료 API를 사용한다.
  - 자본의 흐름을 분석하여 경제 활동을 예측하고 최적의 의사결정을 내리기 위해 사용

### Scipy
- Scientific Python. Numpy base, but advanced.
- 단순한 수학 연산을 넘어 최적화, 보간(interpolation), 선형 대수, 신호 처리, 확률 분포 및 통계 분석, 미적분 계산, Fast Fourier Transform 등과 같은 고급 과학 계산 기능을 지원

### 기술 통게(Descriptive Statistics)
- 데이터를 요약·정리하여 중앙 경향성, 산포도, 분포 형태 등의 지표를 계산하고 시각적으로 표현하는 분석 기법
- 중앙 경향성(Central Tendency) : 중심값을 나타내는 지표. (ex. mean, median, mode)
- 산포도(Dispersion) : 중심 값으로부터 얼마나 퍼져있는지 나타내는 지표. (ex. variance, std)
- 분포 특성(Distribution Characteristics) : 데이터 전체의 형태 (ex. 대칭성 Skewness, 첨도 Kurtosis)

### 가설 검정(Hypothesis Testing)
- 표본을 기반으로 통계적 가설의 참과 거짓을 검정하여 결론을 도출하는 과정
  - 가설 : 특정 현상이나 변수 간의 관계에 대해 실험이나 관찰을 통해 검증 가능한 형태로 제시된 진술
- 귀무가설(Null Hypothesis) : 기본적으로 참이라고 가정하는 가설 -> 연구자가 반증하고자 하는 대상
- 대립가설(Alternative Hypothesis) : 검정하고자 하는 가설 -> 귀무가설과 반대
- 1종 오류 : 귀무가설이 참인데 잘못 기각하는 오류 -> 효과가 없는데 있다고 판단하는 실수
- 2종 오류 : 대립가설이 참인데 귀무가설을 기각하지 않는 오류 -> 효과가 있는데 없다고 판단하는 실수
- p값 : 귀무가설이 참일 때 현재 표본보다 극단적인 결과가 나올 확률 -> p값이 0.03 : 현재 표본이 우연하게 나올 확률이 3% 밖에 되지 않으므로 차이가 있다고 보겠다.
- "비타민을 먹으면 집중력이 향상될까?"
  - 귀무가설 : "비타민을 먹어도 집중력에 차이가 없다."
  - 대립가설 : "비타민을 먹으면 집중력이 향상된다."
  - 표본 데이터를 기반으로 검정 통계량(Test Statistic)을 계산, 이를 확률적으로 해석하여 귀무가설을 기각할지 결정
