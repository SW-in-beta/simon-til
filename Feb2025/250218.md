# 머신러닝

### TensorFlow, Keras
- 대세는 Pytorch 라고 한다. Keras(고수준) < TensorFlow(저수준, 계산 위주)
- 일단 이런게 있다 정도만 알고 가자

### Pytorch
- 코드가 좀 더 직관적이라 학계에서 선호한다고 한다. (Alex said, 아름답다)
- 실무는 아직이긴 하지만 그래도 점점 확장되는 편이라고 한다.
- 딥러닝 라이브러리지만 머신러닝도 한다.
- 그래디언트를 쉽게 계산할 수 있고, 역전파도 알아서 수행해주는 듯. 오... 역시...
- TensorFlow에 비해 Pytorch가 동적이고 유연하다고 한다.
  - 하지만 TensorFlow가 배포는 더 잘 지원해준다네

### 데이터 전처리
- Library가 원하는 데이터를 줘야한다
  - Missing value, outlier, 데이터 정규화, 데이터 변환 등
- 데이터 전처리에만 시간을 30% 이상 소요하는 경우가 많다.

### 데이터 증강
- 전처리의 과정 중 하나. 기존 데이터를 변형하여 새로운 데이터를 생성
  - 이미지에 회전, 크기조절, 색상변호, 노이즈 추가 등등...
  - 문장을 다른 언어로 번역했다가 다시 원래 언어로 번역하는 것도 포함
- 역시나 왜곡이 있을수도 있어서 분명한 한계가 존재한다.
  - 금융 데이터나 정형 데이터에는 특히나 적합하지 못한 방법이다.

### 데이터셋 분할
- 원본 데이터를 학습 데이터 + (검증 데이터) + 테스트 데이터로 나누는 기법
  - 학습 데이터를 검증에 다시 푸는건 별로...
  - 검증 데이터 : 하이퍼파라미터를 튜닝하는데 사용되는 데이터 -> 교차 검증 등의 방법을 사용할 경우 굳이 안해도 된다.
  - 하이퍼파라미터 : 모델에 있는 파라미터 말고 모델을 학습하는데 필요한 파라미터(경사하강법 step 등)
- 과적합 방지, 성능 평가, 일반화 확인, 하이퍼파라미터 튜닝, 비교 연구(다른 모델과의) 등에 사용
- 보통 학습데이터 : 테스트데이터 = 8 : 2 정도로 한다.(8 : 2라는 비율 자체도 하이퍼파라미터네~)

### 머신러닝
- 기계가 자동으로 학습한다! -> 학습 자체가 자동이라는건 아니다.. 어떻게 학습하라는지 설명하지 않아도 된다는 이야기. 데이터셋 주고 이런건 사람이 해야지
- 그러다보니 얘가 뭐가 좋은지 안좋은지 구분을 못함 -> 질 좋은 데이터가 많아야 잘 공부한다.

### 딥러닝
- 대량의 데이터를 기반으로 비선형 모델을 자동으로 만들어주는 기법 -> **비선형** **자동**이 핵심이다!
- 세상은 보통 비선형으로 되어있지 않을까.
- 모델 설계(신경망의 구조. ex. 층 수, 뉴런 개수, 활성화 함수 등 -> 하이퍼파라미터)와 초기화(weight, bias) 과정이 매우 중요하다.
  - 주요 하이퍼파라미터 : 학습률, 배치 크기, 에폭, 드롭아웃 비율 등
    - 학습률 : 가중치를 업데이트 하는 속도(ex. 경사하강법에서 기울기 * -1 * 학습률만큼 움직이기)
    - 배치 크기 : 한 번에 학습하는 데이터 샘플 수 -> 배치 크기가 크면 메모리 사용 많지만 학습은 안정적
    - 에폭 : 데이터를 몇회독하는지 -> 너무 많이하면 Overfitting
  - 활성화 함수 : 비선형성을 추가하는 요소(ReLU, Sigmoid)
- 예전에 공부했던 개념들이 슬슬 나오기 시작한다. 여기서 실제로 만들어보면서 하면 그때 공부했던 것들이 이렇게 쓰이는구나.. 하고 알 수 있을 것 같아서 신난다.

### 퍼셉트론 내가 이해한대로 정리하기
- 단층 퍼셉트론 => 입력 : k차원, 출력 : 스칼라
  - 퍼셉트론은 입력과 동일한 k차원의 벡터 w(weights)와 스칼라 b(bias), 활성화함수 f를 갖는다.
  - 입력이 들어오면 w와 k의 내적에 b를 더한 값이 계산(x라고 하자)된다.
  - 계산된 x를 활성화 함수의 input으로 넣어 반환된 y를 반환한다! => 반환되는 값은 스칼라
- 다층 퍼셉트론에서 n번째 layer에서 받는 입력은? => n-1번째 layer에 있는 퍼셉트론들의 y들을 모은 벡터를 입력으로 받는다.
  - n-1번째 layer에 k개의 퍼셉트론이 있다면 n번째 layer의 퍼셉트론이 받는 input은 k차원의 벡터
  - 아래 코드에서 layer1은 2개의 퍼셉트론, layer2는 1개의 퍼셉트론으로 구성된다.(출력의 크기와 같다.)
  - layer1의 퍼셉트론 개수가 2개이므로 2차원의 벡터가 layer2의 퍼셉트론 입력으로 주어지는데, 아래 코드에서 보면 layer2의 입력크기를 3으로 설정했으니 실제로는 에러가 발생한다.
``` Python
class XORModel(nn.Module):
    def __init__(self):
        super(XORModel, self).__init__()
        self.layer1 = nn.Linear(2, 2)  # 첫 번째 선형 레이어, 입력 크기 2, 출력 크기 2
        self.layer2 = nn.Linear(3, 1)  # 두 번째 선형 레이어, 입력 크기 3, 출력 크기 1
        self.relu = nn.ReLU()  # ReLU 활성화 함수
        self.sigmoid = nn.Sigmoid()  # Sigmoid 활성화 함수

    def forward(self, x):
        x = self.relu(self.layer1(x))  # 첫 번째 레이어와 ReLU 적용
        x = self.sigmoid(self.layer2(x))  # 두 번째 레이어와 Sigmoid 적용
        return x
```