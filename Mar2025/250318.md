# 개인 공부

### Keras를 활용한 RNN 구현
- SimpleRNN(hidden_units, input_shape=(timpesteps, input_dim))
    - hidden_units : Hidden State의 크기. 17일에 공부한 내용에서의 D_h.
    - timesteps : input sequence의 길이
    - input_dim : input의 사이즈. 17일에 공부한 내용에서의 d.
    - W_x(input과 곱해지는 weight)의 사이즈 : hidden_units * input_dim -> 즉 hidden_units * 1이 Hidden State가 된다.
    - hidden_units의 크기는 중소형 모델의 경우 보통 128, 256, 512, 1024 정도.
- RNN 층은 (batch_size, timesteps, input_dim) 크기의 3D 텐서를 입력으로 받는다.
- 최종 시점에서의 은닉 상태만을 리턴하고자 한다면 (batch_size, output_dim) 크기의 2D 텐서 리턴, 각 시점의 은닉 상태값들을 모아서 리턴하고 싶으면 (batch_size, timesteps, output_dim) 리턴
    - SimpleRNN의 return_sequences를 True로 하면 각 시점의 은닉상태 모두 리턴 가능
    - 다음 층에 RNN 은닉층이 하나 더 있는 경우 return_sequences를 True로 설정하면 된다.
- Q. Embedding Layer에 Input을 넣을 때 따로 one-hot Encoding을 하지 않는다. Embedding Layer를 생성할때 vocab_size를 주니까 알아서 변환해주는건가?
- A. 맞다! keras는 똑똑하다.
- Q. Tokenizer를 X_train에 맞춰 fit_on_texts를 하였다. 즉 X_train에 있는 단어들로 인덱스화를 했는데, 만약 X_train에 없던 단어가 X_test에 있다면?
- A. 무시된다. 근데 Tokenizer를 생성할 때 oov_token="<OOV>"를 주면 처음 보는 단어를 "<OOV>"에 해당하는 인덱스로 변환한다.(주로 가장 마지막 인덱스. 그리고 아마 Out Of Value)
- Q. 비슷한 맥락에서, X_train의 최장길이에 맞춰 pad_sequence를 했으므로, 훈련된 모델은 X_train의 최장길이 만큼의 timestep을 input으로 받는다. 만약 X_test에 더 긴 시퀀스가 있다면?
- A. pad_sequence의 maxlen에 맞춰 짤린다.

### LSTM(Long Short-Term Memory)
- Vanila RNN(이하 RNN)의 문제점 : Sequence가 길어질수록 초기 시점의 정보가 얕아진다 -> 장기 의존성 문제(the problem of Long-Term Dependencies)
    - 기울기 소실의 문제. 역전파를 하면서 그래디언트 체이닝을 거듭할수록 기울기가 작아진다. -> 초기 시점의 그래디언트가 미미해진다.
- LSTM은 은닉 상태를 계산하는 식이 더 복잠 -> 은닉 상태와 더불어 셀 상태(Cell State)를 추가.
- 셀 상태도 마찬가지로 이전 시점에서의 셀 상태가 다음 시점의 셀 상태를 구하기 위한 입력으로 사용된다.
- Q. 셀 상태가 RNN의 은닉 상태를 대체하는 개념이 아니고 같이 사용되는건가? -> 현재 셀 상태를 구하기 위해 간접적으로 이전 은닉 상태를 사용한다. 그리고 현재 은닉 상태는 현재의 셀 상태를 사용한다. 결국 출력되는 값은 현재의 은닉 상태
    - 셀 상태는 "장기 메모리", 은닉 상태는 "단기 메모리" + "현재 출력할 내용"
    - 즉, C_t는 문맥을 유지하는 "장기 기억", h_t는 그 문맥을 기반으로 즉각적인 출력을 내는 "단기 출력" 역할을 한다.
- 은닉 상태와 셀 상태를 구하기 위해 입력/출력/삭제 게이트 추가 -> 각 게이트에는 시그모이드 함수가 존재하고, 반환된 0~1 값을 가지고 게이트를 조절
    - 각 게이트별로 x_t와 h_t-1를 위한 W가 각각 따로 존재한다.(ex. W_xi, W_xo, W_hi, W_ho). 물론 bias도(ex. b_i, b_o).
        - 결국 여기도 x_t와 h_t-1의 가중합으로 뭔가를 판단한다. 즉 Weight를 학습시켜야 한다는 의미. 모든 것이 Weight로 표현된다.
        - x_t와 곱해지는 W_x는 '현재 시점에서 새로 입력되는 정보를 얼마나 반영할지'를 반영
        - h_t-1과 곱해지는 W_h는 '현재 시점에서, 이전의 정보를 얼마나 기억할지'를 반영
        - 결국 같은 식이라도, Weight의 역할에 따라 다르게 학습이 된다.
    1. 입력 게이트 : i_{t}=σ(W_{xi}x_{t}+W_{hi}h_{t-1}+b_{i}), g_{t}=tanh(W_{xg}x_{t}+W_{hg}h_{t-1}+b_{g}). 
        - 즉 시그모이드 함수를 지나는 웨이트 W_xi, W_hi와 하이퍼볼릭 탄젠트 함수를 지나는 W_xg, W_hg가 존재.
        - i_{t} : 현재 정보를 얼마나 반영할지 결정하는 게이트 값
            - 0에 가까울수록 새로운 정보를 거의 반영하지 않겠다 <-> 1에 가까울수록 새로운 정보를 강하게 반영하겠다.
            - 즉 새로 입력되는 정보를 얼마나 반영할지를 "비율"로 조절
        - g_{t} : 새롭게 추가될 정보의 내용
            - 현재 시점에서 기억할 정보의 "내용"을 결정
            - 입력값 x_t와 이전 은닉 상태 h_t-1을 이용해서 새로운 후보 정보를 만든 것
        - i_{t}∘g_{t} : 새로운 정보를 얼마나 추가할지 결정
            - g_t 자체가 새롭게 추가될 정보의 내용인데, i_t가 없다면 항상 모든 정보를 기억해야 하는 문제가 생긴다. -> 기억한다 = 출력값에 영향을 많이 미친다.
            - i_t가 존재함으로써 새로운 정보를 선택적으로 반영할 수 있다.
    2. 삭제 게이트 : f_{t}=σ(W_{xf}x_{t}+W_{hf}h_{t-1}+b_{f})
        - 이 값이 삭제 과정을 거친 정보의 양. 0에 가까울수록 정보가 많이 삭제 / 1에 가까울수록 정보를 온전히 기억
        - 삭제 게이트를 통해서 결정되는 것은 셀 상태(C_t). 즉 학습과정에서 다음 시점에 현재의 상태가 얼마나 관여할지를 Back Propagation을 통해 학습한다.
    -> 입력 게이트는 현재 시점의 입력을 얼마나 반영할지를 결정하고, 삭제 게이트는 이전 시점의 입력을 얼마나 반영할지를 결정한다.
    3. 셀 상태 : C_{t}=f_{t}∘C_{t-1}+i_{t}∘g_{t}
        - ∘ : 원소별 곱(entrywise product)
        - i_{t}∘g_{t} : 입력 게이트에서 구한 두 출력의 원소별 곱. 이것이 이번에 선택된 기억할 값
        - f_{t}∘C_{t-1} : 이전 셀 상태와 삭제 게이트의 원소별 곱 -> 즉 일부 기억을 잃은 상태. 이렇기 때문에 삭제 게이트 출력값이 0에 가까운 원소가 삭제되고 1에 가까운 원소가 기억되는 것
        - 삭제 게이트의 출력값이 0에 가까울수록 이전 시점의 셀 상태보다 입력 게이트의 결과값의 영향력이 더 커진다.
        - 반대로 입력게이트의 i_t의 값이 0에 가까워 진다면 이전 시점의 셀 상태에 더 의존하게 된다.
        <!-- - 이 셀 상태는 현재 시점의 출력 결과(h_t)에 영향을 주는 것이 아니다!!! 즉, 다음 시점의 출력에 현재의 상태를 얼마나 전달할지를 결정한다. -->
    4. 출력 게이트 : o_{t}=σ(W_{xo}x_{t}+W_{ho}h_{t-1}+b_{o})
        - 입력 게이트의 i_t/삭제 게이트의 f_t와 유사하다. 
        - 그러나 출력 게이트는 셀 상태에는 전혀 지장을 주지 않고, 최종적으로 은닉 상태에만 관여를 한다. -> 어떤 정보를 '기억'할지보다 '출력'할지에 더 중점을 둔다.
    5. 은닉 상태 : h_{t}=o_{t}∘tanh(c_{t})
        - Q. 과연 이게 의미하는 바가 뭘까.
        - A. C_t는 다음 시점으로 전달될 주요 정보기도 하지만, 결국은 과거의 정보와 현재의 정보가 합쳐져서 업데이트된 결과이다. 너무 크거나 작은 값이 될 수 있어서 tanh를 사용해 정규화해준다. 그리고 그 결과를 그대로 출력하지 않고, 이걸 얼마나 출력해주면 좋을까?를 출력 게이트의 출력값을 곱해줌으로써 조절한다.
    - Q. 삭제 게이트가 0에 가까울수록 정보가 많이 삭제된다. 근데 입력 게이트에도 h_t가 사용되지 않나. 그렇다면 이것도 이전 시점을 반영한다고 할 수 있지 않을까?
        - A. 맞다. 그래도 주요 역할 자체가 다르고, 간접적으로 반영되는 것이다. 입력 게이트에서 이전 시점을 반영하는 역할은 그렇게 크지 않다.
    - Q. i_t와 g_t가 같이 존재하는 이유도 여전히 의문이다. -> 해결!
    - Q. i_t와 g_t는 단지 활성화 함수가 시그모이드냐 하이퍼볼릭 탄젠트냐의 차이 뿐인데 어떻게 역할을 분리해서 학습이 되지...
    - Q. 어떻게 동작하는지 알겠어. 근데 시점에 따라 기억해야할 정보의 양이나 새로 받아들여야할 정보의 양이 다를텐데, RNN과 LSTM에서는 매 시점마다 같은 Weight를 사용하잖아? 그건 어떻게 해결이 돼?


- 다른 소린데... 보면 다 웨이트가지고 뭘 한다. 웨이트를 가지고 기억할 정보, 삭제할 정보 이런것도 다 판단하고... 결국 뭘 시키려고 하든 웨이트를 가지고 너는 무슨 기능이야!하고 학습시키면 되는 느낌
- 이걸 내가 일일이 넌 뭘 기억해야하니까 웨이트가 얼마고 뭘 삭제시켜야 하니까 웨이트가 얼마고 이렇게 하려면 절대 불가능. 역시 대단하다 딥러닝